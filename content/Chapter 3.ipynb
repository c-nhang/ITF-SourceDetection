{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Distance-based Source Estimator\n\nDistance centrality is a proven suboptimal heuristic to approximate the optimal solution for finding the source ([Shah, 2011](https://doi.org/10.1109/TIT.2011.2158885)). It achieves the optimal solution for degree-regular trees, like rumor centrality. The calculation of the distance-based source estimator offers a more efficient and scalable solution when compared to the rumor source estimator, particularly in the context of undirected graphs. This is because distance centrality focuses on the proximity of a vertex to all other vertices in the network, which can be computed with algorithms that have lower computational complexity than those required for rumor centrality. Distance centrality captures the influence of a vertex based on its accessibility, making it a powerful and straightforward measure of influence that avoids the extensive tree transformations and complex calculations involved in rumor centrality. This efficiency becomes even more apparent in large-scale networks, where the scalability of algorithms is a critical concern. The distance-based source estimator can handle larger graphs with more nodes and edges, providing quicker and more reliable results. This is particularly beneficial in real-world applications like social media analysis, transportation networks, and biological networks, where the ability to swiftly analyze and interpret network data can lead to more informed decisions and insights. Because of its simplicity and efficiency, distance centrality also allows for easier interpretation and implementation, making it an attractive option for network analysts and researchers for finding the network source.\n\nLet $G=(V(G), E(G))$ be a simple connected graph. Denote the shortest distance between two vertices, say $u$ and $v$, by $\\text{dist}(u,v)$. The distance centrality of a vertex $v\\in V(G)$, $S(v, G)$, is defined as \n$$\n    S(v,G) = \\displaystyle\\sum_{w\\in V(G)}\\text{dist}(v, w).\n$$\nThe distance center, $C_{\\text{dist}}(G)$, of $G$ is a vertex with the smallest distance centrality.",
      "metadata": {
        "user_expressions": [],
        "trusted": true
      },
      "id": "a252cb6f-ae37-4c2c-8e50-854e9a2488fa"
    },
    {
      "cell_type": "markdown",
      "source": "## Graph Analytics Library",
      "metadata": {
        "user_expressions": [],
        "trusted": true
      },
      "id": "b051d54a-b56c-47bd-8ec5-daf8ceedb82c"
    },
    {
      "cell_type": "markdown",
      "source": "Before diving into the implementation of a function to identify the distance-based source estimator, it is crucial to familiarize oneself with two prominent graph analytics libraries. Graph analytics libraries play an important role in network and graph analysis as they provide efficient data structures, algorithms, and tools necessary for handling complex network data, facilitating the extraction of meaningful insights, and enabling the solving of complex problems related to connectivity, flow, and structure. These libraries enhance the process of graph manipulation and analysis, making it accessible even for those who may not have a deep understanding of the underlying graph theory. Utilizing such libraries enhances the efficiency, accuracy, and scalability of network-related computations, which is particularly important in fields like social network analysis, bioinformatics, transportation, and telecommunication, where networks can be massive and complex. Hence, having a solid grasp of these graph analytics libraries is indispensable for anyone looking to perform advanced network and graph analytics.\n\n1. *NetworkX* ([Hagberg, 2008](https://www.osti.gov/biblio/960616)) is a powerful Python library designed for the creation, analysis, and visualization of complex networks, providing a versatile toolset that caters to a wide array of network applications. It facilitates the manipulation of both directed and undirected graphs, allowing for the storage of nodes and edges with associated metadata. NetworkX stands out for its ease of use and flexibility, offering an extensive collection of algorithms that cover various domains including graph theory, social network analysis, and network science. Users can leverage NetworkX to compute shortest paths, find network clusters, measure centrality, and more. Its integration with standard Python libraries like NumPy, SciPy, and Matplotlib enhances its functionality, enabling efficient numerical computations and high-quality visualizations. Despite its focus on simplicity, NetworkX does not compromise on performance for small to medium-sized networks, making it a popular choice among researchers, educators, and data scientists for experimenting with and analyzing networked systems. The library’s open-source nature and active community further contribute to its continuous development, ensuring it remains a reliable and up-to-date resource for network analysis.\n\n2. The *Stanford Network Analysis Project (SNAP)* ([Leskovec, 2016](https://doi.org/10.48550/arXiv.1606.07550)) is a comprehensive library and research initiative developed to facilitate the analysis, modeling, and visualization of large-scale network data. Originating from Stanford University, SNAP provides an extensive set of tools and algorithms designed to work efficiently with networks containing millions of nodes and edges. It supports various programming languages, including C++ and Python, and offers functionalities to handle diverse network types, from social networks and web graphs to biological networks. With a focus on both performance and ease of use, SNAP enables researchers and practitioners to delve into network analysis, uncovering patterns, detecting anomalies, and deriving insights from complex relational data. The project also encompasses a rich collection of network datasets, which serves as a valuable resource for empirical studies and benchmarking. Through its robust features and extensive documentation, SNAP has become an influential platform in the network analysis community, fostering innovation and facilitating interdisciplinary research in network science.",
      "metadata": {
        "user_expressions": [],
        "trusted": true
      },
      "id": "02428b31-ea77-4405-be30-4ae001d2c544"
    },
    {
      "cell_type": "markdown",
      "source": "In this chapter, we will use the NetworkX library as an example to implement the distance-based source estimator.",
      "metadata": {
        "user_expressions": [],
        "trusted": true
      },
      "id": "01d2687c-5378-4dd6-85c4-005cc1aa5208"
    },
    {
      "cell_type": "code",
      "source": "import networkx",
      "metadata": {
        "trusted": true
      },
      "execution_count": 1,
      "outputs": [],
      "id": "3df981da-57a3-415f-850b-d10537c8e84e"
    },
    {
      "cell_type": "code",
      "source": "class Node:\n    def __init__(self, nodeId, dis):\n        self.nodeId = nodeId\n        self.dis = dis\n        self.exact = False\n        \n    def updateLower(self, lowerBound):\n        if lowerBound > self.dis:\n            self.dis = lowerBound\n        \n    def updateDis(self, dis):\n        self.dis = dis\n        self.exact = True\n    \n    def isExact(self):\n        return self.exact\n    \n    def returnNodeId(self):\n        return self.nodeId\n    \n    def returnDis(self):\n        return self.dis\n\nclass PriorityQueue(object): \n    def __init__(self):\n        self.queue = [] \n  \n    def __str__(self):\n        return ' '.join([str(i) for i in self.queue]) \n  \n    # for checking if the queue is empty \n    def isEmpty(self):\n        return len(self.queue) == [] \n  \n    # for inserting an element in the queue \n    def insert(self, data):\n        self.queue.append(data) \n  \n    # for popping an element based on Priority \n    def extractMin(self):\n        try: \n            minS = 0\n            for i in range(len(self.queue)): \n                if self.queue[i].returnDis() < self.queue[minS].returnDis(): \n                    minS = i \n            item = self.queue[minS] \n            del self.queue[minS]\n            return item \n        except IndexError: \n            print() \n            exit() \n            \ndef getMinDegreeV(G):\n    #node_degree_dict = {}\n    minDeg = 99999999\n    minDegV = -1\n    for NI in G.Nodes():\n        if NI.GetDeg() < minDeg:\n            minDegV = NI.GetId()\n    return minDegV\n\ndef calLowerBound(G):\n    global nodesList\n    seed = G.GetRndNId()\n    #print(seed)\n    #seed = 107\n    \n    #find the min degree vertex\n    seed = getMinDegreeV(G)\n    largestDisFromSeed = snap.GetNodeEcc(G,seed, False)\n    NodeNum, NodeVec = G.GetNodesAtHop(seed, largestDisFromSeed, False)\n    seed = NodeVec[0]\n    \n    #BfsTree = snap.GetBfsTree(G, seed, False, False)\n    myQueueLower = PriorityQueue()\n    myQueueUpper = PriorityQueue()\n    C = {}\n    j = 1\n    Sv = 0\n    while True:\n        s = snap.TIntV()\n        snap.GetNodesAtHop(G, seed, j, s, True)\n        if len(s) != 0:\n            C[j] = s\n            Sv = Sv + len(s) * j\n            j = j + 1\n        else:\n            break\n    root = Node(seed, Sv)\n    nodesList[seed] = root\n    myQueueLower.insert(root)\n    '''print 0, \" \", seed\n    for cluster in C:\n        for nodeId in C[cluster]:\n            print cluster, \" \", nodeId, \" \", C[cluster].Len()'''\n    maxL = len(C)\n    for i in range(1, maxL + 1):\n        sumLevel = i\n        for j in range(1, maxL + 1):\n            if abs(i - j) < 1 or abs(i - j) == 1:\n                sumLevel = sumLevel + 2 * C[j].Len()\n            else:\n                sumLevel = sumLevel + abs(i - j) * C[j].Len()\n        for nodeId in C[i]:\n            deg = G.GetNI(nodeId).GetDeg()\n            lowerBound = sumLevel - deg - 2\n            currNode = Node(nodeId, lowerBound)\n            nodesList[nodeId] = currNode\n            myQueueLower.insert(currNode)\n    return myQueueLower\n\ndef ExactTotalDis(G, node):\n    #print \"src \", node.returnNodeId()\n    j = 1\n    Sv = 0\n    while True:\n        s = snap.TIntV()\n        snap.GetNodesAtHop(G, node.returnNodeId(), j, s, True)\n        if len(s) != 0:\n            Sv = Sv + len(s) * j\n            global edgeVisited\n            edgeVisited = edgeVisited + len(s)\n            print(len(s))\n            j = j + 1\n        else:\n            break\n    return Sv\n\ndef UpdateLowerBound(seed, G):\n    global nodesList\n    C = {}\n    j = 1\n    Sv = 0\n    while True:\n        s = snap.TIntV()\n        snap.GetNodesAtHop(G, seed, j, s, True)\n        if len(s) != 0:\n            C[j] = s\n            Sv = Sv + len(s) * j\n            global edgeVisited\n            edgeVisited = edgeVisited + len(s)\n            j = j + 1\n        else:\n            break\n    nodesList[seed].updateDis(Sv)\n    maxL = len(C)\n    for i in range(1, maxL + 1):\n        sumLevel = i\n        for j in range(1, maxL + 1):\n            if abs(i - j) < 1 or abs(i - j) == 1:\n                sumLevel = sumLevel + 2 * C[j].Len()\n            else:\n                sumLevel = sumLevel + abs(i - j) * C[j].Len()\n        for nodeId in C[i]:\n            deg = G.GetNI(nodeId).GetDeg()\n            lowerBound = sumLevel - deg - 2\n            nodesList[nodeId].updateLower(lowerBound)\n\ndef Pruning(Gp):\n    G = snap.ConvertGraph(type(Gp), Gp)\n    M = 1\n    N = Gp.GetNodes()\n    T = {}\n    D = {}\n    for node in Gp.Nodes():\n        nodeId = node.GetId()\n        T[nodeId] = 1\n        D[nodeId] = 0\n        \n    continuePruning = True    \n    while continuePruning:\n        continuePruning = False\n        for node in Gp.Nodes():\n            nodeId = node.GetId()\n            deg = node.GetDeg()\n            if deg == M and N > 1:\n                parent = node.GetNbrNId(0)\n                T[parent] = T[parent] + T[nodeId]\n                D[parent] = D[parent] + T[nodeId] + D[nodeId]\n                continuePruning = True\n                Gp.DelNode(nodeId)\n                N = N - 1\n    #print(T)\n    #print(D)\n\nimport pandas as pd\nimport snap\nimport time\n\nedgeVisited = 0\nnodesList = {}\n\nif __name__ == '__main__':\n    graphDF = pd.read_csv('tweets_graph.csv', encoding = \"latin-1\")\n\n    allNamesList = []     \n    for index, row in graphDF.iterrows():\n        src = row['Src']\n        dst = row['Dst']\n        allNamesList.append(src)\n        allNamesList.append(dst)\n\n    allNamesList = list(set(allNamesList))\n\n    indexToNameDict = {}\n    for index, val in enumerate(allNamesList):\n        indexToNameDict[index] = val\n\n    NameToIndexDict = {}\n    for index, val in enumerate(allNamesList):\n        NameToIndexDict[val] = index\n\n    srcList = []\n    complete_G = snap.TUNGraph.New()\n    for index, row in graphDF.iterrows():\n        src = row['Src']\n        dst = row['Dst']\n        src = NameToIndexDict[src]\n        dst = NameToIndexDict[dst]\n        if not complete_G.IsNode(src):\n            complete_G.AddNode(src)\n        if not complete_G.IsNode(dst):\n            complete_G.AddNode(dst)\n        complete_G.AddEdge(src, dst)\n        srcList.append(src)\n\n    for NI in complete_G.Nodes():\n        NID = NI.GetId()\n        if complete_G.IsEdge(NID, NID):\n            complete_G.DelEdge(NID, NID)\n    \n    oldV = complete_G.GetNodes()\n    oldE = complete_G.GetEdges()\n\n    max_cc_G = complete_G.GetMxScc()\n    ccOldV = max_cc_G.GetNodes()\n    ccOldE = max_cc_G.GetEdges()\n            \n    tStart = time.time()\n    \n    Pruning(max_cc_G)\n    newV = max_cc_G.GetNodes()\n    newE = max_cc_G.GetEdges()\n\n    queue = calLowerBound(max_cc_G)\n    numBFS = 1\n    while True:\n        minNode = queue.extractMin()\n        if minNode.isExact() == True:\n            print(minNode.returnNodeId(), \" \", minNode.returnDis())\n            break\n        else:\n            lowerBound = minNode.returnDis()\n            UpdateLowerBound(minNode.returnNodeId(), max_cc_G)\n            numBFS = numBFS + 1\n            #print(lowerBound, \" \", minNode.returnDis())\n            if minNode.returnDis() == lowerBound:\n                print(minNode.returnNodeId(), \" \", minNode.returnDis())\n                break\n            else:\n                queue.insert(minNode)\n    tEnd = time.time()\n    speedup = (ccOldV * ccOldE)/(edgeVisited + (ccOldV - newV))\n    print(tEnd - tStart)\n    print(speedup)",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "a86bf27d-67dd-4ede-b392-0f7ef9556702"
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "e91cc0df-6e98-4864-9fb3-c340298709ab"
    },
    {
      "cell_type": "markdown",
      "source": "### References\n\n1. Hagberg, A., Swart, P., & S Chult, D. (2008). Exploring network structure, dynamics, and function using NetworkX (No. LA-UR-08-05495; LA-UR-08-5495). Los Alamos National Lab.(LANL), Los Alamos, NM (United States).\n2. Leskovec, J., & Sosič, R. (2016). SNAP: A general-purpose network analysis and graph-mining library. ACM Transactions on Intelligent Systems and Technology (TIST), 8(1), 1-20.\n3. Shah, D., & Zaman, T. (2011). Rumors in a network: Who's the culprit?. IEEE Transactions on information theory, 57(8), 5163-5181.\n4. Hang, C. N., Yu, P. D., Chen, S., Tan, C. W., & Chen, G. (2023). MEGA: Machine Learning-Enhanced Graph Analytics for Infodemic Risk Management. IEEE Journal of Biomedical and Health Informatics.",
      "metadata": {
        "user_expressions": [],
        "trusted": true
      },
      "id": "d643dafd-b660-4248-b44a-03abeddf3e46"
    }
  ]
}